# -*- coding: utf-8 -*-
"""wasteClassification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-F-EZxD-qCgx34on8VC88YqSDTixMYBc

#IMPORTING DATASET FROM KAGGLE
"""

! pip install -q kaggle

from google.colab import files
files.upload()

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download -d techsash/waste-classification-data

! unzip waste-classification-data.zip

"""#IMPORTING LIBRARIES


"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tqdm import tqdm
import cv2
from keras.models import Sequential
from keras.layers import InputLayer, Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, BatchNormalization
from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
from keras.utils import plot_model
from glob import glob
from collections import Counter
import zipfile
import shutil
import os
import random
from sklearn.metrics import classification_report,confusion_matrix
from sklearn import metrics

"""#DATA PREPARATION AND VISUALISATION"""

paths = ["DATASET/TRAIN/","DATASET/TEST/"]

train_path=paths[0]
test_path=paths[1]

x_data = []
y_data = []

for category in glob(train_path+'/*'):
    for file in tqdm(glob(category+'/*')):
        img_array=cv2.imread(file)
        img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)
        x_data.append(img_array)
        y_data.append(category.split("/")[-1])

data=pd.DataFrame({'image': x_data,'label': y_data})

data.shape

Counter(y_data)

colors = ['#a0d157','#c48bb8', '#a20f35']
plt.pie(data.label.value_counts(),startangle=90,explode=[0.05,0.05],autopct='%0.2f%%',
        labels=['Organic', 'Recyclable'], colors= colors,radius=2)
plt.show()

"""**DEFINING LABELS**"""

labels=[]
for folder in os.listdir(paths[0]):
    labels.append(folder)

dicc_labels = {i:label for i, label in enumerate(os.listdir(paths[0]))}
dicc_labels

"""**RESIZING IMAGE**"""

n=[]
s=80
_images=[]
_labels=[]
for j in range(0,2):
  for i,folder in enumerate(labels):
      try:
          for image in os.listdir(paths[j] +'/'+folder):
              img = os.path.join(paths[j]+'/'+folder+'/'+image)
              img = cv2.imread(img)
              img = cv2.resize(img,(s,s))
              img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
              #img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  #if you want to use scale gray
              _images.append(img)
              _labels.append(i)
      except:
          print("siuu")
  n.append(len(_images))

_images = np.asarray(_images)
_labels = np.asarray(_labels).astype('int64')
# print("number of images-> ",_images.shape)
print("amount of data per label-> ",np.bincount(_labels))

"""**VISUALIZING DATA**"""

plt.figure(figsize=(25,25))
for i in range(0,24):
    pos= random.randint(0,int(11111+13966))
    plt.subplot(6,6,i+1)
    plt.imshow(_images[pos])
    plt.axis('off')
    plt.title('Organic' if _labels[pos]==1 else 'Recyclable')

"""**SCALING IMAGES (FOR FASTER WORKFLOW)**"""

from sklearn.preprocessing import StandardScaler
scal = StandardScaler()
_images =_images.reshape((len(_images),-1))
scal.fit(_images)
_images_scal = scal.transform(_images)

n #number of images

"""#DATA PROCESSING

**CREATING TRAINING AND TESTING SET**
"""

X_train=_images_scal[0:n[0]]
y_train=_labels[0:n[0]]

X_test=_images_scal[n[0]:n[1]]
y_test=_labels[n[0]:n[1]]


X_train =X_train.reshape(len(X_train),s,s,3)
X_test = X_test.reshape(len(X_test),s,s,3)

print("training images-> ",X_train.shape,"labels train-> ",y_train.shape)
print("training labels by category-> ",np.bincount(y_train))
print("testing images-> ",X_test.shape,"labels train-> ",y_test.shape)
print("testing labels by category-> ",np.bincount(y_test))



"""#NEURAL NETWORK ARCHITECTURE"""

input_shape = (s, s, 3)

model = Sequential([
    InputLayer(input_shape=input_shape),
    Conv2D(s, kernel_size=3, activation="relu", padding="valid"),
    MaxPooling2D(pool_size=(2,2)),
    Dropout(0.5),
    Conv2D(s*2, kernel_size=3, activation="relu", padding="valid"),
    MaxPooling2D(pool_size=(2,2)),
    Dropout(0.5),
    Conv2D(s//2, kernel_size=3, activation="relu", padding="valid"),
    MaxPooling2D(pool_size=(2,2)),
    Dropout(0.5),
    Flatten(),
    Dense(1, activation="sigmoid")
])

model.compile(optimizer="adam", loss="binary_crossentropy",
               metrics=["accuracy","Precision"]
)

model.summary()

plot_model(model)

"""**TRAINING THE MODEL**"""

history=model.fit(X_train, y_train, validation_batch_size=(X_test,y_test),epochs=30)

"""**LOSS GRAPHS**"""

acc = history.history['accuracy']
loss = history.history['loss']
prec = history.history['precision']


epochs = range(1, len(acc) + 1)

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.title('Training accuracy')
plt.legend()

plt.figure()

plt.plot(epochs, loss, 'bo', label='Training loss')
plt.title('Training loss')
plt.legend()

plt.figure()

plt.plot(epochs, prec, 'bo', label='Training precision')
plt.title('Training precision')
plt.legend()

plt.show()

"""**TESTING THE MODEL**"""

pred = model.predict(X_test)
pred=np.where(pred >= 0.5, 1, 0)
print(classification_report(
    y_test,
    pred
))

"""**CONFUSION MATRIX**"""

cm=confusion_matrix(y_test,pred)
cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [False, True])
cm_display.plot()
plt.show()

"""**SAVING THE MODEL**"""

model.save("model.h5")
# folder_to_zip = '/content/model'

# # Define the name for your zip file
# zip_filename = '/content/waterClassificationModel.zip'

# # Create a zip file object
# with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:
#     # Iterate over all the files and folders in the directory
#     for root, _, files in os.walk(folder_to_zip):
#         for file in files:
#             # Create the full path to the file
#             file_path = os.path.join(root, file)
#             # Add the file to the zip
#             zipf.write(file_path, os.path.relpath(file_path, folder_to_zip))

"""#MODEL PREDICTION"""

def predict_func(img):
    plt.figure(figsize=(6, 4))
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    plt.tight_layout()

    n=[]
    s=80

    img = cv2.resize(img, (80, 80))

    # Convert image to float32 and normalize
    img = img.astype(np.float32) / 255.0

    # Expand dimensions to match the input shape expected by the model
    img = np.expand_dims(img, axis=0)

    img = np.asarray(img)

    # print(img)

    # Predict
    result = model.predict(img)
    result=np.where(result >= 0.35, 1, 0)
    print(result)
    if result == 1:
        print("\033[94m" + "This image -> Recyclable" + "\033[0m")
    elif result == 0:
        print("\033[94m" + "This image -> Organic" + "\033[0m")

_images =_images.reshape(len(_images),s,s,3)
plt.figure(figsize=(25,25))
for i in range(0,24):
    pos= random.randint(0,int(n[1]-n[0]))
    plt.subplot(6,6,i+1)
    plt.imshow(_images[n[0]+pos])
    plt.axis('off')
    plt.title("pred-> %s     real-> %s "%(dicc_labels[pred[pos][0]],dicc_labels[y_test[pos]]))

img_path="/content/DATASET/TEST/O/O_12617.jpg"
img=cv2.imread(img_path)
predict_func(img)